<!DOCTYPE html>
<html lang="en">
<head>
	<title>Methodology | Women Writers Vector Toolkit</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
	<link rel="shortcut icon" href="/utils/gfx/favicon.ico" />
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script> 
	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
	<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
	<link rel="stylesheet" href="../styles/main.css">
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
	<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,400italic,600&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css"/>
</head>
<body>
	<header>
		<nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
			<div class="container">
				<div class="d-inline-flex">
					<img src="../assets/logo.png" width="61" height="52" class="d-inline-block align-top" alt="">
					<a href="../index.html" id="wwvt-home">Women Writers Vector Toolkit</a>
				</div>
				<div>
					<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
						<span class="navbar-toggler-icon"></span>
					</button>
					<div class="collapse navbar-collapse" id="navbarResponsive">
						<ul class="navbar-nav ml-auto">
							<li class="nav-item">
								<a class="nav-link" href="http://lab.wwp.northeastern.edu/wwvt/">Word Vector Interface</a>
							</li>
							<li class="nav-item dropdown">
								<a class="nav-link dropdown" data-toggle="dropdown" href="../about/about-wwvt/index.html" id="about" aria-haspopup="true" aria-expanded="false">
									About
									<i class="fa fa-caret-down"></i>
								</a>
								<div class="dropdown-menu" aria-labelledby="about">
									<a class="dropdown-item" href="../about/about-wwvt/index.html">About the WWVT</a>
									<a class="dropdown-item" href="../about/navigate/index.html">How to Navigate</a>
									<a class="dropdown-item" href="../about/team/index.html">Team</a>
								</div>
							</li>
							<li class="nav-item dropdown">
								<a class="nav-link dropdown" data-toggle="dropdown" href="../resources/glossary/index.html" id="resource" aria-haspopup="true" aria-expanded="false">
									Resources
									<i class="fa fa-caret-down"></i>
								</a>
							  <div class="dropdown-menu" aria-labelledby="resource">
							    <a class="dropdown-item" href="../resources/introduction/index.html">Introduction</a>
									<a class="dropdown-item" href="../resources/glossary/index.html">Glossary</a>
									<a class="dropdown-item" href="../resources/case-studies/index.html">Case Studies</a>
							    <a class="dropdown-item" href="../resources/sources/index.html">Helpful Sources</a>
							    <a class="dropdown-item" href="../resources/walkthroughs/index.html">Code Walkthroughs</a>
							    <a class="dropdown-item" href="../resources/downloads/index.html">Downloads</a>
								</div>
							</li>
							<li class="nav-item dropdown">
								<a class="nav-link dropdown" data-toggle="dropdown" href="../teaching-exploration/index.html" id="teaching"  aria-haspopup="true" aria-expanded="false">
									Teaching Guide
									<i class="fa fa-caret-down"></i>
								</a>
								<div class="dropdown-menu" aria-labelledby="teaching">
									<a class="dropdown-item" href="../teaching-exploration/index.html">Teaching with this Tool</a>
									<a class="dropdown-item" href="../teaching-exploration/assignments/index.html">Assignments</a>
								</div>
							</li>
							<li class="nav-item">
								<a class="nav-link" href="../methodology/index.html">Methodology</a>
							</li>
						</ul>
					</div>
				</div>
			</div>
		</nav>
	</header>

	<div class="main-body">
		<div class="wwp-text">
			<div class="container">
				<div class="row justify-content-center">
					<div class="col">
					  
					  <h1>Methodology</h1>
    
						  <section>
  					    <h2>The Word Vector Interface</h2>
     						<p><a href="https://github.com/NEU-DSG/word-vector-interface" class="link link-external" target="_blank">Code for the Word Vector Interface</a> can be found on GitHub. 
     							The Interface itself is an <a href="https://shiny.rstudio.com" class="link link-external" target="_blank">RStudio 
     							Shiny</a> application developed by Jonathan D. Fitzgerald and Parth Tandel. It uses Benjamin Schmidt’s R package 
     							<a href="https://github.com/bmschmidt/wordVectors" class="link link-external" target="_blank">wordVectors</a> (which itself includes a version of Tomas Mikolov’s original <a href="https://github.com/tmikolov/word2vec" target="_blank">code for word2vec</a>)
     						  to train and query word embedding models.</p>
     						<p>The GitHub repository includes the models used in the Word Vector Interface, as well as a JSON catalog 
     						  containing descriptions of those models.</p>
						  </section>

							<section>
							  <h2>Corpora</h2>
							  <p>The Word Vector Interface is powered by three collections of documents from three different projects. 
								  Each corpus was transcribed and encoded in XML, following the guidelines of the 
									<a href="https://www.tei-c.org/" class="link link-external" target="_blank">Text Encoding Initiative (TEI)</a>. 
							    By using texts marked up in TEI, we were able to make nuanced choices about the textual features used to generate 
							    the files on which we trained the word embedding models.
								  <!--For this project, the XML files were gathered and then transformed into normalized plain text using 
									<a href="https://github.com/NEU-DSG/wwp-public-code-share/tree/main/fulltext" 
									class="link link-external" target="_blank">XSLT and XQuery scripts</a> (described in  below).--></p>
								<p>The Women Writers Project’s <a href="https://wwp.northeastern.edu/wwo/texts" target="_blank">Women Writers Online</a>
								  (WWO) corpus collects works which were authored, translated, or compiled by women, published between 1526 and 1850. The 
								  corpus is available online to subscribing institutions or individuals (find <a href="https://wwp.northeastern.edu/wwo/license/">information on one-month free trials</a> on the WWP website). The XML files are freely 
									available on request. For consideration, send an email with a brief description of your research to 
									<a href="mailto:wwp@&#x006E;ortheastern&#x002E;&#x0065;&#x0064;&#x0075;">wwp@&#x006E;ortheastern&#x002E;&#x0065;&#x0064;&#x0075;</a>.</p>
								<p>The Interface also includes models trained on texts from the <a href="https://webapp1.dlib.indiana.edu/vwwp/welcome.do;jsessionid=D4020148F707FB298ED2B48F992EDFDC">Victorian Women Writers Project</a> (VWWP), as well as the 
									<a href="https://quod.lib.umich.edu/e/eebogroup/" class="link link-external" target="_blank">Early English Books Online</a> 
									(EEBO), <a href="https://quod.lib.umich.edu/e/ecco/" target="_blank">Eighteenth-Century Collections Online</a> (ECCO), and <a href="https://quod.lib.umich.edu/e/evans/" target="_blank">Evans Early American Imprint</a> TEI texts published by the <a href="https://www.textcreationpartnership.org/" target="_blank">Text Creation Partnership</a> (TCP). From the vast TCP corpus, we selected sub-corpora which roughly mirror the WWO corpus
								  in number of words per century. The VWWP began at Indiana University in 1995 and is concerned with the exposure of lesser-known British women writers of the 19th century. The collection contains a range of genres, including: poetry, novels, children’s books, political pamphlets, religious tracts, and histories.</p>
							 
								

								<h3>Corpus Preparation</h3>
							  <p>In order to get plain text out of the WWO XML, we transformed the corpus using a suite of tools written in
							    XSLT and XQuery, native programming languages for XML documents. The XSLT stylesheet uses TEI encoding to make nuanced choices about 
							    significant textual content. For example, abbreviations are expanded and errors are corrected
							  	within our text outputs, based on the encoding with <code>&lt;abbr&gt;</code> and <code>&lt;expan&gt;</code>, and with <code>&lt;sic&gt;</code> and <code>&lt;corr&gt;</code> elements.</p>
								<!-- Snapshot example of XML/TEI and transformed text -->
								<p>In addition to transforming the output based on particular elements, we use XQuery scripts to remove elements that skew results 
								  with word embedding models, such as speaker labels in drama. Modern writing, such as metadata and text written by WWP encoders and staff, 
								  are also removed. The XQuery scripts also allow us to construct sub-corpora by extracting specified sections of XML documents using XPath.</p>
								<!-- Full list: ('castList', 'elision', 'figDesc', 'label', 'speaker') with an example -->
							  <p>These tools can be found in the <a href="https://github.com/NEU-DSG/wwp-public-code-share/tree/main/fulltext" class="link link-external" 
  target="_blank">WWP Public Code Share</a> on GitHub.</p>
								<p>We have also included two models with some additional regularization, using the routines developed by the <a class="link link-external" href="https://graphics.cs.wisc.edu/WP/vep/" target="_blank">Visualizing English Print</a> project: a version of the full WWO corpus and one including only the language attributable to WWO authors. Full details on the VEP project’s regularization routines are available in the <a class="link link-external" href="https://github.com/uwgraphics/VEP-pipeline" target="_blank">VEP-Pipeline GitHub repository</a> and <a class="link link-external" href="https://graphics.cs.wisc.edu/WP/vep/workflow-2/#4_Spelling_Standardization" target="_blank">documentation</a>—we borrow their code with thanks and appreciation.</p>					
			

								<h3>Corpus Parsing</h3>
								<p>The Women Writers Vector Toolkit (WWVT) provides various models for exploration and comparison. <!--We have 
									segmented the WWO corpus into different subsets to create different models. -->In addition to two models that include 
									every file in the WWO (one including front and back matter and one with exclusively the main body of each text), the interface also 
									offers the option to compare models by publication date and by genre.</p>
								<p>The WWO corpus spans more than three centuries and includes information on the date of each text’s first edition, making the corpus 
								  ideal for exploring changes in word usage over time. Publication dates are used to sort and combine documents by their century of publication, 
									with each sub-corpus containing all the documents published in a single century, except for the 16th and 17th centuries, which are combined. 
									The 16th and 17th centuries together provide enough words for a more accurate model and
									are approximately the same size as the 18th- and 19th-century models. These models can be used for 
								diachronic studies of literary and cultural change.</p>
								<p>To create proxies for genre, we were able to leverage TEI encoding of document structures.
									For example, the interface contains two models, one trained on a corpus with exclusively the contents of paragraphs (the TEI <code>&lt;p&gt;</code> element) and the other with the contents of line groups (the TEI <code>&lt;lg&gt;</code> element), enabling a 
									basic comparison between prose and verse.</p>
								<p>Another corpus drawn from WWO’s TEI markup is the “authorial” corpus, which includes only those textual contents written by WWO authors, and excludes tables of contents, indices, editorial prefaces and dedications, subscriber lists, and so on. This corpus was prepared using the “<a href="https://github.com/NEU-DSG/wwp-public-code-share/tree/main/fulltext" class="link link-external" 
									target="_blank">FulltextBot</a>,” an XSLT stylesheet developed by Ash Clark and Sarah Connell that is available in the WWP’s GitHub repository. </p>
							  <p>We also used TEI markup to create several corpora in which names of places and persons were tokenized by inserting underscores between words inside of <code>&lt;persName&gt;</code> and <code>&lt;placeName&gt;</code> elements and removing extraneous spaces and punctuation. These corpora were prepared using the “<a href="https://github.com/NEU-DSG/wwp-public-code-share/blob/main/fulltext/Element-Tokenizer-README.md" class="link link-external" 
									target="_blank">Element Tokenizer</a>,” an XSLT stylesheet developed by Juniper Johnson and Ash Clark that is available in the WWP’s GitHub repository.
								</p>

								<h3>TCP Corpora Preparation and Parsing</h3>
								<p>The TCP corpora are designed as parallels to the WWO corpus, approximating the word-counts per century in Women 
								Writers Online. To collect texts from the TCP files, we used a Python script which counts the words in the plain-text 
								versions of each text and then uses publication date metadata to select a subset of texts from the 
								TCP collection with approximately the same number of words per century as in the WWO collection. In the future, we plan
								 to use more precise methods for creating parallel corpora, drawing on the markup to select
								 texts with similar numbers of <code>&lt;l&gt;</code>, <code>&lt;p&gt;</code>, and <code>&lt;sp&gt;</code> 
								elements, for example, to ensure a rough balance in genres between the texts in the two corpora.</p>
								<!--<p>First, each document in the EEBO corpus is categorized by the century in which it was originally published: 17th century, 
									18th century, or 19th century. Documents without a source publication date are passed over. Once the century has been 
									identified, the document’s source author, publication date, and publication place are added to a tab-separated 
								catalog.</p>
								<p>Then, the document’s textual content (from <code>&lt;text&gt;</code>) is minimally regularized. Newlines and tabs are reduced to a 
									single space. Word by word, with whitespace used as a delimiter, the long-s character (“ſ”) is regularized to “s”. <!-\- I think this needs to be more separate statements? -\->
									Each word is added to the matching century subcorpus as well as the all-centuries EEBO subcorpus. At the same time, 
								the Python script increments the total number of words gathered for the given century.</p>
								<p>When a particular century has a total word-count that meets or exceeds the target word-count, no further documents 
								from that century will be added to the subcorpora or the catalog.</p>-->
              </section>
						  
						  <section>
								<h2>Model Testing</h2>
								<p>Once the plain text of each file has been cleaned, normalized, sorted, and combined, the resulting text files can be used to train models with word2vec. To choose the best-fitting parameters for 
									our data, we compared models’ cosine similarities of word pairs that, based on our knowledge of these corpora, we expect to have high degrees of similarity (such as: “before” and “after”; “father” and “mother”; “king” and “prince”; and “holy” and “sacred”). We found that we obtained the best results 
									from a model created with a window size of 6 words, 100 vectors, 10 iterations, and negative sampling set at 15. Models 
								produced from the smallest datasets varied slightly with an optimal negative sampling at 5.</p>
								<p>With the model parameters in place, we then tested our three regularization processes: XSLT and XQuery alone; 
								  Northwestern University’s <a href="http://morphadorner.northwestern.edu/morphadorner/" class="link link-external" target="_blank">MorphAdorner</a>; 
								  and MorphAdorner tuned to be sensitive to Early Modern English vocabularies and 
									spelling practices. We again tested models with word pairings and found that the XSLT and XQuery alone produced the best 
								results. In the future, we plan to test other methods for text regularization, and add models that have been
								trained on the same corpora, but with different regularization processes, to allow for comparison. We will also
								add more robust methods for validation, updating our models based on the results of that validation, and publishing 
								our validation routines, along with the code used to train the models, in this space.</p>
							</section>
						  
						  <section>
						    <h2>Downloads</h2>
						    <p>For links to view and download the routines and code for this project, see our <a href="../resources/downloads/index.html">Downloads page</a>.</p>
						  </section>
						
						
					</div>
				</div>
			</div>
		</div>
	</div>
	<script type="text/javascript" src="../scripts/mobile-dropdown.js" ></script>
</body>
</html>
